# ðŸ”§ Setup: GitHub Actions + Neon.tech

Esta guÃ­a te ayudarÃ¡ a configurar completamente la automatizaciÃ³n del crawler con GitHub Actions y Neon.tech (PostgreSQL).

---

## **Fase 1: Preparar Neon.tech**

### Paso 1: Crear una base de datos en Neon

1. Ve a [https://console.neon.tech](https://console.neon.tech) (o crea una cuenta si no tienes)
2. Crea un nuevo proyecto (Project)
3. Selecciona:
   - **Region:** Elige la mÃ¡s cercana a tu ubicaciÃ³n (ej: `us-east-1` si usa GH Actions)
   - **Database name:** `jobs` (o el nombre que prefieras)
4. Click en "Create project"

### Paso 2: Obtener la URL de Connection Pooling (Transaction)

1. En el dashboard de Neon, ve a tu proyecto
2. En la secciÃ³n de "Connection", verÃ¡s varias opciones:
   - **Direct connection** (evitar)
   - **Pooler connection** (usar ESTA)
3. Selecciona el **Pooler** y asegÃºrate de que el dropdown muestra **"Transaction"** mode
4. Copia la URL completa. LucirÃ¡ asÃ­:
   ```
   postgresql://neondb_owner:XXXXXXXX@ep-xxxxx.region.neon.tech/neondb?sslmode=require&pgbouncer=true
   ```

âš ï¸ **IMPORTANTE:** 
- `?sslmode=require` â†’ SSL obligatorio (Neon lo requiere)
- `?pgbouncer=true` â†’ Activa Transaction Pool (ideal para GitHub Actions)
- **NO cambies esta URL** en tu `.env` local, solo Ãºsala en GitHub Secrets

### Paso 3: Validar la conexiÃ³n (opcional, local)

```bash
# Actualiza temporalmente .env:
DATABASE_URL="postgresql://neondb_owner:XXXXXXXX@ep-xxxxx.region.neon.tech/neondb?sslmode=require&pgbouncer=true"

# Genera cliente Prisma
npm run prisma:generate

# Crea la estructura base de datos en Neon (ESTO SOLO CORRE UNA VEZ)
npm run prisma:migrate

# Con esto se crea la tabla "jobs" en Neon

# Luego restaura .env a SQLite si quieres seguir desarrollando localmente:
DATABASE_URL="file:./prisma/dev.db"
```

---

## **Fase 2: Configurar GitHub Secrets**

### Paso 1: Ir a GitHub

1. Ve a tu repositorio en GitHub
2. Navega a: **Settings** â†’ **Secrets and variables** â†’ **Actions**
3. Click en **"New repository secret"**

### Paso 2: Crear el Secret DATABASE_URL

1. **Name:** `DATABASE_URL`
2. **Value:** Pega la URL completa de Neon que copiaste en Fase 1, Paso 2
   - Ej: `postgresql://neondb_owner:XXXXXXXX@ep-xxxxx.region.neon.tech/neondb?sslmode=require&pgbouncer=true`
3. Click en **"Add secret"**

âœ… Ahora GitHub Actions tendrÃ¡ acceso a la URL de la base de datos sin exponerla en el cÃ³digo.

---

## **Fase 3: Verificar el Workflow**

### Paso 1: Prueba manual del workflow

1. Ve a tu repositorio â†’ **Actions**
2. Busca el workflow llamado **"Job Web Scraper"**
3. Click en el workflow
4. Click en **"Run workflow"** â†’ **"Run workflow"** (botÃ³n azul)

### Paso 2: Monitorear la ejecuciÃ³n

1. El workflow comenzarÃ¡ a ejecutarse
2. VerÃ¡s los pasos en orden:
   - âœ… Checkout code
   - âœ… Setup Node.js
   - âœ… Cache npm / Playwright
   - âœ… Install dependencies
   - âœ… Install Playwright browsers
   - âœ… Generate Prisma Client
   - âœ… Build TypeScript
   - âœ… Cleanup old jobs (0 jobs en primera ejecuciÃ³n)
   - âœ… Run crawler
3. Si todo es verde âœ…, Â¡el crawler executÃ³ exitosamente en Neon!

### Paso 3: Verificar datos en Neon

1. Ve al dashboard de Neon
2. Click en **"SQL Editor"**
3. Ejecuta:
   ```sql
   SELECT COUNT(*) as total_jobs FROM jobs;
   SELECT * FROM jobs LIMIT 10;
   ```
4. DeberÃ­as ver los jobs scraped ðŸŽ‰

---

## **Fase 4: Configurar la ejecuciÃ³n automÃ¡tica**

### Paso 1: Verificar el schedule

El workflow estÃ¡ configurado para ejecutarse **diariamente a las 08:00 UTC**.

Si quieres cambiar la hora, edita [`.github/workflows/scraper.yml`](.github/workflows/scraper.yml):

```yaml
on:
  schedule:
    - cron: '0 8 * * *'  # Cambia estos nÃºmeros
    # Formato: 'minuto hora dia mes dayofweek'
    # Ej: '30 14 * * 1' = 14:30 UTC todos los lunes
```

### Paso 2: Verificar que corre automÃ¡ticamente

- El workflow correrÃ¡ automÃ¡ticamente cada dÃ­a a la hora configurada
- Puedes ver el historial en **Actions** â†’ **Job Web Scraper**
- GitHub enviarÃ¡ notificaciones por email si falla (opcional, configurable)

---

## **Troubleshooting**

| Problema | SoluciÃ³n |
|----------|----------|
| âŒ "Error: Invalid DATABASE_URL" | Verifica que el Secret estÃ¡ configurado correctamente en GitHub. Compara con la URL de Neon. |
| âŒ "Too many connections" | Usar Transaction pooling ya previene esto. Si persiste, aumenta el pool size en Neon dashboard. |
| âŒ "Playwright timeout" | Aumenta el timeout en [src/crawler/jobCrawler.ts](src/crawler/jobCrawler.ts#L93-L94) |
| âŒ "No jobs found" | Revisa que los selectores en `sites.csv` sean correctos. El workflow mostrarÃ¡ los sitios procesados en los logs. |
| â³ Workflow muy lento | Cache de npm/Playwright deberÃ­a activarse en segunda ejecuciÃ³n. Primera vez tarda ~3-4 min. |

---

## **PrÃ³ximos Pasos**

1. âœ… Migrar data existente de SQLite a Neon (si tienes datos):
   ```bash
   # Exportar de SQLite
   npm run prisma:studio  # Ver data en interfaz grÃ¡fica
   
   # Luego migrar manualmente o con script customizado
   ```

2. âœ… Monitorear logs del crawler:
   - Ver en GitHub Actions â†’ "Run crawler" step
   - Cada ejecuciÃ³n mostrarÃ¡ logs de sitios, jobs encontrados, errores

3. âœ… Ajustar `DAYS_TO_CHECK` en [src/index.ts](src/index.ts#L9) si necesitas
   - Default: Ãºltimos 7 dÃ­as

4. âœ… Modificar frecuencia de cleanup en [scripts/cleanup-old-jobs.ts](scripts/cleanup-old-jobs.ts#L11)
   - Default: borrar jobs > 30 dÃ­as

---

## **Resumen: URLs y Valores**

| Elemento | DÃ³nde obtener |
|----------|--------------|
| **Neon Project URL** | https://console.neon.tech |
| **Pooler Connection** | Neon Dashboard â†’ Connection â†’ Pooler â†’ Transaction |
| **GitHub Secrets** | Repositorio â†’ Settings â†’ Secrets â†’ DATABASE_URL |
| **Workflow File** | [`.github/workflows/scraper.yml`](.github/workflows/scraper.yml) |
| **Cleanup Script** | [`scripts/cleanup-old-jobs.ts`](scripts/cleanup-old-jobs.ts) |

---

**Estado:** âœ… ImplementaciÃ³n completada  
**PrÃ³ximo:** Crear cuenta Neon â†’ Obtener URL â†’ Configurar Secret â†’ Ejecutar workflow

