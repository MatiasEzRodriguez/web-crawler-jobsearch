# ğŸ—ï¸ Arquitectura: GitHub Actions + Neon.tech

Detalles tÃ©cnicos de la automatizaciÃ³n implementada.

---

## **Schema Prisma Actualizado**

**Cambio principal:** SQLite â†’ PostgreSQL

```prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"  // â† Cambio de "sqlite"
  url      = env("DATABASE_URL")
}

model Job {
  id        Int     @id @default(autoincrement())
  title     String
  company   String
  url       String  @unique
  postedDate DateTime
  foundAt   DateTime @default(now())
  
  @@map("jobs")
}
```

**Por quÃ© PostgreSQL:**
- âœ… Mejor escalabilidad que SQLite
- âœ… Soporta conexiones concurrentes (GH Actions)
- âœ… Neon ofrece tier gratuito generoso (10GB storage)
- âœ… No hay file-based database (evita problemas de concurrencia)

---

## **Workflow: EjecuciÃ³n Paso a Paso**

### Architecture Diagram

```
GitHub Actions Runner (ubuntu-latest)
â”‚
â”œâ”€ 1. Checkout repo
â”œâ”€ 2. Setup Node 18
â”œâ”€ 3. Restore npm cache (si existe)
â”œâ”€ 4. Restore Playwright cache (si existe)
â”‚  
â”œâ”€ 5. npm ci (instala deps, usa cachÃ© si disponible)
â”‚  â””â”€ Packages: @prisma/client, playwright, date-fns, csv-parser, ts-node
â”‚
â”œâ”€ 6. npx playwright install chromium (usa cachÃ© si disponible)
â”‚  â””â”€ Descarga ~150MB Chromium (una sola vez, luego cachÃ©)
â”‚
â”œâ”€ 7. npx prisma generate
â”‚  â””â”€ Genera @prisma/client basado en schema.prisma
â”‚
â”œâ”€ 8. npm run build
â”‚  â””â”€ Compila TypeScript â†’ dist/
â”‚
â”œâ”€ 9. npx ts-node scripts/cleanup-old-jobs.ts
â”‚  â””â”€ DATABASE_URL â†’ Neon
â”‚  â””â”€ DELETE jobs WHERE foundAt < 30 days ago
â”‚  â””â”€ Log: "Deleted X jobs"
â”‚
â”œâ”€ 10. npm start (ejecuta dist/index.js)
â”‚  â””â”€ DATABASE_URL â†’ Neon  
â”‚  â””â”€ Scrape sitios en sites.csv
â”‚  â””â”€ Guardar jobs nuevos en Neon
â”‚  â””â”€ On error: log y continue (graceful degradation)
â”‚
â””â”€ 11. Finish
```

---

## **Variables de Entorno: GitHub Secrets**

```yaml
env:
  DATABASE_URL: ${{ secrets.DATABASE_URL }}
```

**Flujo de seguridad:**
1. Secret criado en GitHub (Settings â†’ Secrets)
2. GitHub Actions inyecta en una variable de entorno cifrada
3. El code accede via `process.env.DATABASE_URL`
4. La variable se redacta en los logs (GitHub oculta valores de secrets)

**Valor esperado (Neon):**
```
postgresql://user:password@ep-xxxxx.region.neon.tech/dbname?sslmode=require&pgbouncer=true
```

---

## **Connection Pooling: Transaction vs Session**

### Transaction Pooling (RECOMENDADO para GH Actions)

```url
postgresql://...?pgbouncer=true&sslmode=require
```

**CaracterÃ­sticas:**
- âœ… Abre conexiÃ³n **solo durante la transacciÃ³n**
- âœ… Cierra despuÃ©s de `COMMIT` o `ROLLBACK`
- âœ… Pool size puede ser muy pequeÃ±o (5-10 conexiones)
- âœ… Ideal para workloads cortos y episÃ³dicos
- âŒ Algunas caracterÃ­sticas SQL avanzadas no funcionan

**Por quÃ© es ideal para GH Actions:**
- Cada runner de GH Actions es efÃ­mero (30 min max)
- El crawler ejecuta 1-2 min mÃ¡ximo
- No necesita mantener conexiÃ³n abierta
- MÃºltiples runners pueden ejecutar en paralelo sin "connection limits"

### Session Pooling (NO recomendado para GH Actions)

```url
postgresql://...?pgbouncer=true&pooling_mode=session&sslmode=require
```

**CaracterÃ­sticas:**
- Mantiene conexiones abiertas por usuario
- Mejor para aplicaciones always-on
- Mayor riesgo de "Too many connections" con mÃºltiples runners

---

## **Cleanup Script: Detalles**

### UbicaciÃ³n
[`scripts/cleanup-old-jobs.ts`](scripts/cleanup-old-jobs.ts)

### LÃ³gica
```typescript
const thirtyDaysAgo = subDays(new Date(), 30);
const result = await prisma.job.deleteMany({
  where: {
    foundAt: { lt: thirtyDaysAgo }
  }
});
```

### CuÃ¡ndo ejecuta
- **Timing:** Antes del crawler (paso 9 en el workflow)
- **Frecuencia:** Cada ejecuciÃ³n del workflow (diariamente a 08:00 UTC)
- **Impacto:** Mantiene BD sin crecer indefinidamente

### Ejemplo de output
```
[Cleanup] Starting cleanup of jobs older than 30 days...
[Cleanup] âœ… Successfully deleted 15 jobs older than 30 days
```

---

## **ParÃ¡metros Neon: ExplicaciÃ³n**

### URL de ConexiÃ³n
```
postgresql://
neondb_owner:XXXXX
@ep-xxxxx.us-east-1.neon.tech  â† Endpoint Ãºnico por proyecto
/neondb                         â† Database name
?sslmode=require                â† SSL obligatorio
&pgbouncer=true                 â† Activa pooler
```

### `sslmode=require`
- âœ… Neon **requiere SSL** (no permite conexiones plaintext)
- GitHub Actions + Neon automÃ¡ticamente usan HTTPS

### `pgbouncer=true`
- Equivalente a usar el endpoint **"Pooler"** en Neon dashboard
- Activar Transaction pooling

### Â¿DÃ³nde obtenerlo?
1. Neon console â†’ Project â†’ Connection
2. Selecciona el branch (main, dev, etc.)
3. Dropdown donde dice "Role:", selecciona tu role (ej: neondb_owner)
4. BotÃ³n "Pooler" â†’ "Transaction"
5. Copia la URL completa

---

## **Decisiones de Arquitectura**

| DecisiÃ³n | RazÃ³n |
|----------|-------|
| **PostgreSQL** | Escalable, soporta concurrencia, Neon gratuito |
| **Transaction Pooling** | Evita "Too many connections", ideal para runners efÃ­meros |
| **npm ci vs npm install** | Determinista y mÃ¡s rÃ¡pido en CI/CD |
| **CachÃ© persistente** | npm cachÃ© ahorra ~1 min/ejecuciÃ³n; Playwright cachÃ© ahorra ~2-3 min/ejecuciÃ³n |
| **Cleanup previo** | Previene crecimiento infinito de la BD |
| **CompilaciÃ³n TS** | `npm run build && npm start` mÃ¡s rÃ¡pido que `ts-node src/index.ts` en prod |
| **Headless: true** | Ya configurado, no requiere X11/display en GitHub runners |
| **Cleanup: 30 dÃ­as** | Balance entre mantener data histÃ³rica y no llenar la BD |

---

## **Monitoreo y Logs**

### En GitHub Actions
- Ve a: Repository â†’ Actions â†’ "Job Web Scraper"
- Click en la ejecuciÃ³n mÃ¡s reciente
- Cada step muestra logs en tiempo real
- Los secrets se redactan automÃ¡ticamente

### Logs del Crawler
El step "Run crawler" mostrarÃ¡:
```
[INFO] === Job Web Crawler Started ===
[INFO] Configuration:
[INFO]   - Days to check: 7
[INFO]   - CSV file: ./sites.csv
[INFO] Processing site: https://getonbrd.com/...
[INFO] Scraped 5 jobs, saved 3
[INFO] === Job Web Crawler Completed ===
```

### Monitoreo en Neon
- Dashboard â†’ SQL Editor
- Query: `SELECT COUNT(*) as total_jobs FROM jobs;`
- Query: `SELECT COUNT(*) as today FROM jobs WHERE DATE(foundAt) = CURRENT_DATE;`

---

## **Performance**

### Primera ejecuciÃ³n (sin cachÃ©)
```
npm install + Playwright install + Build + Cleanup + Crawler = ~4-5 minutos
```

### Segunda+ ejecuciÃ³n (con cachÃ©)
```
Reuse cache + Build + Cleanup + Crawler = ~1-2 minutos
```

### Desglose tÃ­pico (con cachÃ©):
- npm ci: 15 segundos
- Playwright install: 30 segundos (cachÃ©)
- Prisma generate: 5 segundos
- Build TypeScript: 10 segundos
- Cleanup: 5 segundos
- Crawler (5 sitios): 30-60 segundos (incluye esperas entre sitios)
- **Total: ~2 minutos**

---

## **Seguridad**

âœ… **Best Practices Implementadas:**

1. **Secrets** - DATABASE_URL no visible en logs
2. **SSL** - Neon requiere `sslmode=require` (obligatorio)
3. **Connection Pooling** - Evita conexiones abusivas
4. **No hardcoding** - Env vars via GitHub Secrets
5. **Error logging** - Logs sin exponer credenciales
6. **Graceful errors** - Un sitio fallido no detiene el crawler

âš ï¸ **Consideraciones:**

- Neon proporciona una URL unique por proyecto
- GitHub Secrets estÃ¡n encriptados at-rest
- GitHub Actions no expone secrets en outputs por defecto
- No dejar la URL de DATABASE_URL en el repo pÃºblico

---

## **FAQ TÃ©cnicas**

**P: Â¿QuÃ© pasa si la BD no existe cuando corre el workflow?**  
R: Si no ejecutaste las migraciones en Neon, fallarÃ©. SoluciÃ³n: Hacer `npm run prisma:migrate` localmente una sola vez con DATABASE_URL apuntando a Neon.

**P: Â¿Puedo ejecutar mÃºltiples crawlers en paralelo?**  
R: SÃ­, gracias a Transaction Pooling. MÃ¡ximo ~5-10 runners simultÃ¡neos sin problemas de conexiÃ³n.

**P: Â¿La cleanup es obligatoria?**  
R: No, es opcional. Puedes comentar el paso en el workflow si quieres mantener toda la data histÃ³rica.

**P: Â¿Playwright consume mucha memoria?**  
R: GitHub Actions runner tiene 7GB RAM. Para 5 sitios seriales: ~200-300MB (estÃ¡ bien).

**P: Â¿CÃ³mo cancelo una ejecuciÃ³n?**  
R: En GitHub Actions â†’ click en la ejecuciÃ³n en curso â†’ "Cancel workflow run".

---

## **PrÃ³xima OptimizaciÃ³n**

Posibles mejoras futuras:

- [ ] Batch database writes (n jobs por transacciÃ³n vs 1)
- [ ] Parallel site scraping (async Promise.all())
- [ ] Notificaciones por Slack/Email en caso de error
- [ ] MÃ©tricas: Prometheus/CloudWatch de jobs encontrados
- [ ] Cache de resultados para evitar re-scraping mismo dÃ­a
- [ ] API endpoint para consultar jobs (Express server)

